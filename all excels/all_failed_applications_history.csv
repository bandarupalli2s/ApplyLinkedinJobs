Job ID,Job Link,Resume Tried,Date listed,Date Tried,Assumed Reason,Stack Trace,External Job link,Screenshot Name
4260751210,https://www.linkedin.com/jobs/view/4260751210,Pending,Unknown,2025-07-09 00:07:19.192123,Required experience is high,"
About the job
Our client is currently seeking a Senior DevOps Engineer 

Overview
In this role, you will be responsible for the design, development, and deployment of scalable and secure software solutions across the full software development lifecycle. You will work closely with both front-end and back-end technologies, with a strong focus on Java, Spring Boot, Azure (AKS), and DevOps practices.
You will contribute to building robust microservices, integrating cloud-native solutions, and ensuring continuous integration and delivery pipelines are efficient and secure. This role follows Agile development methodologies and requires strong collaboration and problem-solving skills.
Minimum Qualifications
8â€“10 years of experience in software development and DevOps engineering.
Proficiency in Java (1.8, 21) and Spring Boot frameworks.
Experience with cloud platforms, especially Azure and Azure Kubernetes Service (AKS).
Strong understanding of DevOps principles, CI/CD pipelines, and infrastructure automation.
Hands-on experience with Docker, GitHub, and Gradle/Maven.
Familiarity with Unix/Linux environments and shell scripting.
Experience with SQL and NoSQL databases (e.g., Oracle, Cosmos DB, MarkLogic).
Knowledge of microservices architecture and cloud-native design patterns.
Preferred Qualifications
Experience with Azure DataBricks, Azure Data Factory (ADF).
Familiarity with Kafka, Python, and JUnit for testing.
Exposure to Spring Integration and Spring Batch.
Experience with PCF (Pivotal Cloud Foundry) or similar cloud platforms.
Proficiency with development tools such as IntelliJ or Eclipse.
Rate: $70-80/HR

Experience required 10 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4260761965,https://www.linkedin.com/jobs/view/4260761965,resume.pdf,Unknown,2025-07-09 00:08:36.145739,Problem in Easy Applying,"Message: stale element reference: stale element not found in the current frame
  (Session info: chrome=138.0.7204.94); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception
Stacktrace:
0   chromedriver                        0x0000000104db4e6c cxxbridge1$str$ptr + 2722840
1   chromedriver                        0x0000000104dacd74 cxxbridge1$str$ptr + 2689824
2   chromedriver                        0x00000001048fe3ec cxxbridge1$string$len + 90648
3   chromedriver                        0x00000001049040a0 cxxbridge1$string$len + 114380
4   chromedriver                        0x00000001049063e4 cxxbridge1$string$len + 123408
5   chromedriver                        0x000000010490648c cxxbridge1$string$len + 123576
6   chromedriver                        0x0000000104945114 cxxbridge1$string$len + 380736
7   chromedriver                        0x000000010493ade4 cxxbridge1$string$len + 338960
8   chromedriver                        0x0000000104986934 cxxbridge1$string$len + 649056
9   chromedriver                        0x0000000104939834 cxxbridge1$string$len + 333408
10  chromedriver                        0x0000000104d77f88 cxxbridge1$str$ptr + 2473268
11  chromedriver                        0x0000000104d7b1f4 cxxbridge1$str$ptr + 2486176
12  chromedriver                        0x0000000104d599d0 cxxbridge1$str$ptr + 2348924
13  chromedriver                        0x0000000104d7bab0 cxxbridge1$str$ptr + 2488412
14  chromedriver                        0x0000000104d4aa60 cxxbridge1$str$ptr + 2287628
15  chromedriver                        0x0000000104d9b9a0 cxxbridge1$str$ptr + 2619212
16  chromedriver                        0x0000000104d9bb2c cxxbridge1$str$ptr + 2619608
17  chromedriver                        0x0000000104dac9b0 cxxbridge1$str$ptr + 2688860
18  libsystem_pthread.dylib             0x0000000198dc2c0c _pthread_start + 136
19  libsystem_pthread.dylib             0x0000000198dbdb80 thread_start + 8
",Easy Applied,Not Available
4260751210,https://www.linkedin.com/jobs/view/4260751210,Pending,Unknown,2025-07-09 00:17:07.607861,Required experience is high,"
About the job
Our client is currently seeking a Senior DevOps Engineer 

Overview
In this role, you will be responsible for the design, development, and deployment of scalable and secure software solutions across the full software development lifecycle. You will work closely with both front-end and back-end technologies, with a strong focus on Java, Spring Boot, Azure (AKS), and DevOps practices.
You will contribute to building robust microservices, integrating cloud-native solutions, and ensuring continuous integration and delivery pipelines are efficient and secure. This role follows Agile development methodologies and requires strong collaboration and problem-solving skills.
Minimum Qualifications
8â€“10 years of experience in software development and DevOps engineering.
Proficiency in Java (1.8, 21) and Spring Boot frameworks.
Experience with cloud platforms, especially Azure and Azure Kubernetes Service (AKS).
Strong understanding of DevOps principles, CI/CD pipelines, and infrastructure automation.
Hands-on experience with Docker, GitHub, and Gradle/Maven.
Familiarity with Unix/Linux environments and shell scripting.
Experience with SQL and NoSQL databases (e.g., Oracle, Cosmos DB, MarkLogic).
Knowledge of microservices architecture and cloud-native design patterns.
Preferred Qualifications
Experience with Azure DataBricks, Azure Data Factory (ADF).
Familiarity with Kafka, Python, and JUnit for testing.
Exposure to Spring Integration and Spring Batch.
Experience with PCF (Pivotal Cloud Foundry) or similar cloud platforms.
Proficiency with development tools such as IntelliJ or Eclipse.
Rate: $70-80/HR

Experience required 10 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4262821900,https://www.linkedin.com/jobs/view/4262821900,Pending,Unknown,2025-07-09 00:17:35.619928,Asking for Security clearance,"
About the job
General Summary Of Position
Granite has an immediate need for a mid-level Cloud DevOps Engineer to support our ongoing automation and cloud modernization initiative. This role is ideal for a DevOps enthusiast with a solid understanding of cloud computing and passion for streamlining development and deployment processes.
The right candidate will be a self starter, able to work independently or as a team member. Must be able to thrive in a fast-paced environment and learn new technologies quickly. This is a growing company where you will be able to have a significant impact on our internal processes and get a chance to add directly to the goals of the organization.
Duties And Responsibilities
Build, release and maintain CI/CD pipelines to support application development and deployment workflows
Define and document DevOps processes, standards, and tooling in a greenfield cloud environment
Implement and manage Infrastructure as Code (laC) using tools like Terraform
Set up monitoring, logging, and alerting frameworks (e.g., Elastic, Prometheus, Grafana)
Champion automation and self-service wherever possible to improve Developer experience and reduce manual intervention
Collaborate with development teams to optimize build, test, and release pipelines
Integrate DevSecOps practices by embedding automated security and compliance checks (e.g., vulnerability scanning, static code analysis, and secrets management) into CI/CD pipelines
Design and manage cloud IAM policies and roles to enforce least-privilege access, automate user and service account provisioning, and maintain secure identity controls across environments
Assist in defining, designing and implementing cloud strategy and best practices
Lead and support incident response and root cause analysis for cloud infrastructure issues
Mentor junior engineers and help grow a culture of operational excellence 
Required Qualifications
Excellent scripting skills (Bash, Python. Go, or similar)
4+ years of experience in Cloud DevOps and / or Cloud Engineering
Hands-on experience and knowledge of GCP, AWS, OCI or Azure - compute, storage and network operation concepts
2+ years of hands-on experience with Google Cloud Platform (GCP) services such as GKE, Cloud Run, Cloud Functions, Pub/Sub, IAM, and vpc
Strong skills in Terraform, Pulumi, or similar lac frameworks
Proven experience building DevOps pipelines using Azure DevOps, GitHub Actions, Jenkins, or similar tools Proficient in containerization and orchestration (Docker, Kubernetes/GKE)
Solid understanding of networking, security principles, and access control in cloud environments
Experience leading projects in greenfield or early-stage cloud environments
Preferred Qualifications
Familiarity with security controls / concerns around enterprise software, DevSecOps
Certification(s) with Cloud platforms (GCP, Azure or AWS)
Experience with multi-cloud and hybrid environments
Experience with building and managing Al/MLOPs pipelines and infrastructure for Al workloads
Experience with on premises to cloud (public or private) transformation
Experience in Agile Framework (SAFe) and Agile development methodology
Experience with test automation tools and integrating NUnit or JUnit tests
Experience with client server architecture, service-oriented, microservice architecture Experience with Windows and .NET environments

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4260717006,https://www.linkedin.com/jobs/view/4260717006,Pending,Unknown,2025-07-09 00:18:18.892323,Found a Bad Word in About Job,"
About the job
Job Role: OpenShift Administrator (with Linux administration, Automation & DevOps Expertise)
Work Locations:(Pittsburgh-PA/Strongsville-OH/Birmingham-AL/Dallas-TX/Phoenix, AZ)

IMMEDIATE HIRING

Job Summary:

Clarium is seeking a skilled OpenShift Administrator with a strong background in Linux system administration, scripting, automation and DevOps practices. The ideal candidate will be responsible for maintaining and supporting RedHat OpenShift clusters in production environment, providing 24*7 support, incident triage, and participating in release activities. You will work closely with cross-functional teams to ensure system reliability, scalability, and performance.

 
Key Responsibilities:
  Administer and maintain RedHat OpenShift clusters in production and non-production environments. Upgrade Clusters
Perform Linux system administration, troubleshooting, patching
Monitor cluster health, manage node scalability, resource optimization and ensure cluster availability (No downtime)
Troubleshoot and resolve issues related to infrastructure, network, pods, containers, and services
Participate in 24x7 production support (on-call rotation), handle critical incidents, and ensure minimal platform downtime
Develop and maintain shell/python scripts for automation of routine tasks and monitoring
Implement and support CI/CD pipelines using tools like Jenkins, GitOps Approach, or ArgoCD
Collaborate with development and release teams to support deployment and release activities
Create and maintain documentation for systems, processes, and standard operating procedures (SOPs)
Ensure compliance with security, backup, and disaster recovery policies
Platform monitoring using Dynatrace


Required Qualification:

â€¢ 5+ years of hands-on experience with RedHat OpenShift (v4.x preferred).
â€¢ Strong proficiency in Linux (RedHat Linux, CoreOS) system administration.
â€¢ Solid experience in Shell scripting, bash, and/or Python.
â€¢ Knowledge of DevOps tools such as Jenkins, Git, Ansible, Helm, Docker, and GitOps workflows.
â€¢ Understanding of container orchestration, pod scheduling, and cluster level debugging.
â€¢ Experience working in production support environments with on-call responsibilities
â€¢ Familiarity with monitoring and logging solutions such as Prometheus, Grafana, ELK, FluentD.
â€¢ Good problem-solving skills and experience in incident triage and root cause analysis

 Preferred Qualifications:

â€¢ RedHat Certified Specialist in OpenShift Administration or equivalent
â€¢ Certified Kubernetes Administration (CKA)
â€¢ Knowledge of Kubernetes, Istio, or service mesh technologies
â€¢ Experience with Azure cloud platform
â€¢ Experience with ArgoCD workflows


Work Authorization:

Must be authorized to work in the United States. (US Citizen/GC/H1B/GC EAD)

Work Environment:

Fast-paced, enterprise-grade infrastructure with high uptime requirements
Expectation to work during critical incidents, maintenance windows, and release weekends.
Team collaboration across IT operations, development, QA, and DevOps

Compensation & Benefits:

Competitive salary based on experience.
Medical, dental, vision insurance.
401(k) with company match.
Paid time off and holidays.
Professional development opportunities.

Contains bad word ""US Citizen"". Skipping this job!
",Skipped,Not Available
4262178052,https://www.linkedin.com/jobs/view/4262178052,Pending,Unknown,2025-07-09 00:18:21.353884,Found a Bad Word in About Job,"
About the job
Position: Senior Site Reliability Engineer - No C2C
Location: 100% Remote in USA
Duration: Initial 6-month contract, with potential extensions

Overview:
Seeking a Senior Site Reliability Engineer (SRE) to support the development and transformation of its cloud-native technology stack. This role will encompass the full software, data, and infrastructure lifecycle, contributing to the reliability, scalability, and performance of systems. The ideal candidate will have a robust background in financial services, strong leadership abilities, and experience managing platforms that require continuous operation on a 24x6 basis.

Key Responsibilities:
Lead the implementation and transformation of cloud-native technology stack across all SDLC phases.
Ensure the operational continuity and reliability of systems, meeting high availability requirements.
Collaborate across teams to design, deploy, and maintain scalable solutions.
Leverage best practices to manage complex systems and infrastructure in a cloud-native environment.
Provide expertise in building and maintaining resilient, automated platforms.
Monitor system health, resolve incidents, and improve system performance.
Provide leadership in driving platform stability and enhancing operational efficiency.

Qualifications:
Proven experience in financial services or related industries.
Strong leadership and team management skills.
Experience with cloud-native architectures, automation, and infrastructure management.
In-depth knowledge of Site Reliability Engineering practices and tools.
Ability to manage mission-critical platforms with a focus on continuity and performance.
Excellent problem-solving and troubleshooting skills.

Additional Information:
This is a remote position.
The project duration is initially six months, with the possibility of extensions.

Contains bad word ""No C2C"". Skipping this job!
",Skipped,Not Available
4256162359,https://www.linkedin.com/jobs/view/4256162359,Pending,Unknown,2025-07-09 00:18:25.714359,Required experience is high,"
About the job
Senior DevOps Engineer

Position Overview
We are seeking a dynamic individual to fill the role of Senior DevOps Engineer, someone who not only embraces challenges but thrives in proactively solving them. If you are a self-starter with a passion for unraveling the root of issues, automating solutions, and approaching problems from a holistic perspective, this role is for you. In this role, you will be able to help design and implement the backbone of development automation.

Key Responsibilities
Expertise in Kubernetes
Proactive Problem Solver: Identify and address the root causes of issues, focusing on solving problem categories rather than individual instances. Engage early and comprehensively.
Automation Enthusiast: Leverage automation tools such as build and deployment pipelines, Docker, Python, Bash, and Ansible to streamline and eliminate recurring issues.
Multifaceted Expertise: Proficient in CI/CD automation, SDLC, Cloud computing (AWS), Python, Bash, and Ansible, demonstrating versatility across a range of technologies.
Comprehensive Problem Analysis: Conduct thorough investigations to understand all facets of a problem, ensuring comprehensive and effective solutions.
Translate complex problems into manageable, actionable chunks that can be implemented and iteratively improved.
Documentation Excellence: Demonstrate exceptional communication and documentation skills, ensuring clear and comprehensive records for processes, solutions, and potential improvements.
Culture: Strong focus on helping to establish and maintain a DevOps culture, setting development teams up for success by enabling and encouraging self sufficiency

Knowledge, Skills and Experience Required
Bachelorâ€™s degree from an accredited college or university with specialization in an information technology field, equivalent combination of related education and/or work experience totaling a minimum of 8+ years
Expertise in using git and SDLC
Competency in using Linux/UNIX systems
Competency in Cloud Computing, preferably AWS
High proficiency in CI/CD automation workflows, preferably Gitlab
Experience and competency in using containerized systems
Working knowledge of TCP/IP networking
Comfort with utilizing metrics or monitoring solutions for troubleshooting systemic issues
Experience with REST APIâ€™s and webservice solutions is desirable
Ability to perform code reviews in pipeline code (yaml), Docker, Ansible, Python, and Bash
Ability to flexibly adapt to a rapidly changing environment and generate effective and innovative solutions to address change.
Proven record of excellent business judgment and acumen.
Outstanding and persuasive oral and written communication skills that effectively reach all levels of the organization.
Proven ability to prioritize, reprioritize and demonstrates appropriate agility to manage competing and sometimes conflicting priorities.
Demonstrated people leader with experience working on remote teams, including technical mentorship
Experience advising leadership on enhancements and best practices for CI/CD
Strong communication skills with ability to influence at all levels of the organization; ability to simplify complex topics for consumption and critical decision making

Experience required 8 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4264250788,https://www.linkedin.com/jobs/view/4264250788,Pending,Unknown,2025-07-09 00:18:28.311319,Asking for Security clearance,"
About the job
****************Only USC / Green Card/ GC EAD/H4 EAD****************


Position: Sr. DevOps Consultant
Location: Pennington, NJ/Jersey City (Hybrid model) - 3 days onsite
Duration: 18 months
Client: Bank of America
Rate: $70-73/hr on W2. 


Responsible for defining and delivering automated credential management solutions aligning with the enterprise strategy.
Ensures the solution is fit for purpose by working with internal stakeholders as well as external subject matter experts to meet the enterprise needs for secret and credential management.
Consults with business stakeholders to clearly understand the business requirements, challenges of the solution, and finds creative solutions to meet the requirements.
Clarifies the architecture via detailed technical documentation.
Performs design and code reviews to ensure all functional requirements for a solution are sufficiently met

Responsibilities:
As our DevOps engineer, play a crucial role in bridging the gap between development and operations.
Collaborate with cross-functional teams to automate deployment processes and monitoring of infrastructure
Automate the next generation of Privilege Access Vaulting solution with a focus on high-availability and resiliency
Develop and maintain automated solutions leveraging Terraform, Jenkins, Ansible, Git
Managing and optimizing cloud infrastructure on platforms like Azure and AWS
Conducting proactive monitoring and troubleshooting of all systems
Maintaining up-to-date documentation on processes and configurations

Required Qualifications
7+ years of DevOps experience
Strong experience in Ansible, Jenkins, Terraform
Experience taking manual tasks/processes and automated at the enterprise level.
Demonstrated expertise of scripting via common solutions such as Python and PowerShell.
Exposure to working in environment that is heavy on operations technology (automation, optimization, rapid development)
Demonstrated expert level of RHEL Linux OS and LDAP Directory administration.
Solid understanding and demonstrable expertise delivering Linux based automated solutions at enterprise scale.
Solid understanding of infrastructure (hardware, network, storage).
Good understanding of agile methodology and associated toolset (Jira, Bitbucket, Jenkins, etc.)

Desired Qualifications
Previous experience with credential vaulting products such as: CyberArk, Centrify, HashiCorp Secrets Vault.

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4264126298,https://www.linkedin.com/jobs/view/4264126298,Pending,Unknown,2025-07-09 00:18:36.712319,Found a Bad Word in About Job,"
About the job
ðŸŒŸ Principal DevOps Engineer with AI 

Full-Time | Hybrid (3 Days Onsite â€“ New Jersey) | No Visa Sponsorship

Join a Cutting-Edge AI & DevOps Innovation Team
We're seeking a Principal DevOps Engineering Specialist with AI to play a pivotal role in advancing Large Language Model (LLM) capabilities within a modern DevOps ecosystem. This hybrid, full-time position (3 days onsite in New Jersey) is ideal for a hands-on, highly skilled engineer passionate about GenAI, automation, and AI-driven development practices.

ðŸ” What You'll Do
As a core member of the engineering team, you'll:
Drive enhancements to our DevOps processes including automation of requirements gathering, code generation, and test creation.
Design, implement, and refine LLM-based prompts to guide GenAI outputs that are accurate, relevant, and secure.
Contribute to the development of internal tools and frameworks that support software delivery and improve team productivity.
Work collaboratively across cross-functional development teams and third-party vendors to ensure smooth integration and scalable systems.
Stay ahead of the curve by exploring new GenAI techniques, tools, and models to drive innovation.
Lead initiatives in documentation, automation testing, and process reliability.

ðŸ’¡ Tech Youâ€™ll Work With
LLMs (Multiple models)
Microsoft Azure & Azure DevOps Server
GitHub Copilot
Bash, Ansible (Automation tools)
CI/CD, Infrastructure as Code, DevOps frameworks
Service-Oriented Architectures (SOA)

âœ… Your Background
Proven experience improving DevOps pipelines and implementing automation strategies.
Hands-on experience designing prompts and workflows using Generative AI / LLMs.
Knowledge of cloud platforms, especially Azure.
Familiarity with modern software development methodologies and scripting tools.
Strong collaboration and documentation skills.
At least 4â€“6 years of relevant experience and a BA/BS in Computer Science or related field.
2+ years working with LLMs in a development or automation context.

ðŸš« Please Note
No Visa Sponsorship Available â€“ You must be authorized to work in the U.S.
No C2C / No Third-Party Vendors

ðŸ¢ About Hirobe Limited
Expert recruitment, powered by a deep understanding of the Adobe Experience Cloud.
Since 2018, we've been connecting the best Adobe professionals with leading organizations, giving us a unique insight into both the technology and the talent. What truly sets us apart is our specialized market knowledge, tailored service, and unwavering commitment to finding the ideal fit for everyone involved.

ðŸ“¬ Ready to Apply?
This is an urgent hire!
ðŸ“§ Send your resume to: raj@hirobe.io
ðŸ“ž Or call: +1 917-512-8959

Letâ€™s redefine whatâ€™s possible with AI and automationâ€”together.

Contains bad word ""No C2C"". Skipping this job!
",Skipped,Not Available
4258335815,https://www.linkedin.com/jobs/view/4258335815,Pending,Unknown,2025-07-09 00:19:02.340424,Required experience is high,"
About the job
Opportunity is located in the Boca Raton Headquarters onsite 5 days a week.


FinTech, eCommerce company, that provides brand name durable goods to consumers on a lease-to-own (LTO) basis through its ecommerce marketplace and LTO payment method. It also provides LTO technology platforms to retailers and e-tailers to enter transactions with consumers who want to obtain durable goods, but do not have the available cash or credit.

Sponsorship Notice: Applicants must be authorized to work in the United States without the need for current or future visa sponsorship.

We enjoy an accessible fast-paced onsite work environment, where we collaborate with colleagues at all levels of the organization.

FlexShopper is looking for an experienced DevOps Engineer to design and implement cloud-based infrastructure using AWS. This role focuses on scalable architecture design and secure integration with current applications. Key tasks include deploying containerized solutions with Kubernetes and supporting continuous integration and deployment.

Key Responsibilities:
Design enterprise infrastructure for cloud computing, focusing on SaaS, PaaS, and IaaS.
Implement containerized architecture using Kubernetes and support AWS services.
Manage continuous integration, deployment, and configuration management.
Optimize and troubleshoot infrastructure performance, ensuring high availability.
Requirements:
7-10 years experience
Strong experience with AWS, Kubernetes, and container orchestration.
Proficiency in scripting (Bash, Ruby, Python, or Node).
Familiarity with GitOps (Flux or Argo), ELK, and microservice architecture.
Experience with CI/CD tools and Agile methodologies.
Preferred:
Experience scaling MySQL/MongoDB, Node.js, Redis, RMQ, Kafka.
Knowledge of Jenkins, Deis, Rancher, CoreOS, or Mesosphere.

Experience required 7 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4252559741,https://www.linkedin.com/jobs/view/4252559741,Pending,Unknown,2025-07-09 00:19:04.717460,Required experience is high,"
About the job
Weâ€™re hiring experienced Azure Senior DevOps Engineers to join our client's high-impact team driving product-level transformation initiatives. This is a full-time, permanent position requiring onsite work. Weâ€™re looking for individuals who can work independently, think architecturally, and take full ownership of DevOps delivery across cloud infrastructure.

Responsibilities:
Build and integrate robust Azure DevOps pipelines
Provision infrastructure using Terraform
Support and scale Azure IaaS environments
Identify and correct issues in AI-generated code
Collaborate across architecture, engineering, and infrastructure domains
 Qualifications:
7â€“10 years of DevOps experience
2â€“4 years of hands-on experience with Azure Cloud and IaaS
Strong background in infrastructure, architecture, and scripting
Preference for candidates who began in systems administration and evolved into DevOps
Self-directed mindset with a proactive approach to problem-solving
 Why Join:
Youâ€™ll play a central role in a forward-looking technology environment, contributing to strategic transformations with direct business impact. If youâ€™re ready to take the next step in your DevOps career, apply now or message us with questions. Weâ€™d love to connect.

Experience required 10 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4264158371,https://www.linkedin.com/jobs/view/4264158371,Pending,Unknown,2025-07-09 00:19:55.308019,Found a Bad Word in About Job,"
About the job
Title:  Site Reliability Engineer
Location: Miami, FL
Duration: 6+ months
Compensation: $55.00 -60.00
Work Requirements: US Citizen, GC Holders or Authorized to Work in the U.S.
 
Site Reliability Engineer

Description: 
Consultant will play a critical role in ensuring the reliability, performance, and seamless operation of our digital ecosystem. This includes our guest-facing mobile apps, websites, and the backend systems that power them. You will work collaboratively with development, operations, and product teams to build and maintain a highly resilient and scalable digital experience for our guests.

Essential Duties and Responsibilities: 
Incident Response and Resolution: Respond to and resolve production incidents, prioritizing guest-facing issues to minimize disruption. Conduct root cause analysis with guidance from senior team members and implement preventive measures to avoid recurrence.
Monitoring and Observability: Build, maintain, and enhance monitoring tools and dashboards (using Prometheus, Grafana, or similar) to provide visibility into system health, performance, and guest impact. Proactively detect and address potential issues.
Automation and Tooling: Develop and implement automation scripts and tools to streamline operations, reduce manual intervention, and improve system reliability. Utilize configuration management tools and infrastructure as code principles.
Collaboration: Work closely with product teams to incorporate reliability principles into new feature development. Collaborate with operations teams to ensure smooth deployments and transitions.
Documentation and Knowledge Sharing: Create and maintain clear documentation on system architecture, troubleshooting guides, and incident postmortems. Share knowledge and best practices with the team.
On-Call Support: Participate in on-call rotation as defined by team needs, primarily focusing on acknowledging and escalating incidents, with guidance from senior team members.
Working Hours: Expectations of non-standard working hours which include mornings, nights, and weekend rotations.
 
Knowledge and Skills: 
Technical Expertise: Strong knowledge of mobile (iOS, Android) and web technologies, backend systems, cloud infrastructure (AWS, Azure, etc.), and database technologies.
Programming: Proficiency in one or more programming languages (e.g., Python, Java, Go, Jenkins) for scripting and automation. Working knowledge of and Kubernetes a high plus.
Monitoring and Observability: Experience with tools like Prometheus, Grafana, Splunk, or similar.
Incident Management: Experience with incident management tools like PagerDuty, ServiceNow, or similar.
Security: Understanding of security best practices, vulnerability identification, and incident response.
Communication: Excellent written and verbal communication skills for collaborating with diverse teams and stakeholders.
Customer Service: Understands and is aligned to the purpose of providing a great client experience (client focused attitude)
Detailed Oriented: The ability to understand and appreciate the fine, granular details.
SQL Database: Ability to work with large volumes of customer data. Ability to use Oracle SQL (or similar) to query databases and perform edits to SQL queries.
Preferred Qualifications: 
5+ years of demonstrated proficiency in one or more scripting languages such as python, Go, etc
3+ years of experience with Kubernetes or equivalent
5+ years of Software development experience in Java, JavaScript etc.
3+ years of experience with containers and container orchestrators - Docker, Kubernetes
5+ years of demonstrated experience debugging and fixing system/infrastructure and application issues
5+ years of experience working with monitoring tools such as Prometheus, Grafana, Splunk, Google stack driver, etc.
5+ years of experience with databases (SQL or NoSQL)
5+ years of experience with log analysis and building dashboards
At least 6 years in a Reliability Engineering, DevOps or infrastructure focused role
Advanced experience with programming languages ( Python, Java)
Deep systems and infrastructure knowledge
Excellent troubleshooting and problem-solving skills
Experience with high-traffic, guest-facing systems.
Our benefits package includes:
Comprehensive medical benefits
Competitive pay
401(k) retirement plan
...and much more!
About INSPYR Solutions
Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients' business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.

INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities
 
 
Desired Skills and Experience
RELIABILITY ENGINEER
SITE RELIABILITY ENGINEER
SRE
SOFTWARE ENGINEER
DEV OPS ENGINEER
CLOUD
AWS
AZURE
DOCKER
KUBERNETES
PYTHON
JAVA

Contains bad word ""US Citizen"". Skipping this job!
",Skipped,Not Available
4259859439,https://www.linkedin.com/jobs/view/4259859439,Pending,Unknown,2025-07-09 00:19:59.889096,Asking for Security clearance,"
About the job
The Infrastructure Engineer works on holistic engineering deliverables across different stages of the product lifecycle and determines technology patterns for the overall solution. 
  Experience with Kubernetes - OpenShift(OCP) at a platform level
Experience with any one OpenShift / K8s supported Networking CNI. (Plus if you know Calico ) 
Experience with AWS infrastructure (VPC / Security groups / EC2 / Storages / Load Balancers) 
Experience doing OCP upgrades and creating OCP Clusters
Experience of platform automation products like RH ACM / Terraform / Ansible
Responsible for incident resolution and Pager Support on a rotation basis.
Achieves product commitments (and influences others to do the same) by using informal leadership & highly developed communication skills and contributes to or led technology communities.
Uses automation, system tools, open-source solutions, observability and 'security first' principles in daily work 

Preferred Qualifications 
Kubernetes certification like - CKA or CKAD and AWS certification.
Application programming skills in Golang, Java, etc.
Understanding of k8s operator model. 
Scripting languages like shell / Helm modules or some programming experience. 
Diagraming skills such as sequence diagrams, flowcharts, etc.
Concepts of secrets/credential management for Applications and systems - such as use of HashiCorp Vault
Operators in Kubernetes/OCP

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4262882007,https://www.linkedin.com/jobs/view/4262882007,Pending,Unknown,2025-07-09 00:20:18.553171,Required experience is high,"
About the job
Position - Senior Site Reliability Engineer
Location â€“ Charlotte, NC onsite
Contract to hire (C2H)
6 months contract after that convert into fulltime.
 Job Description: 
We are seeking a Senior Site Reliability Engineer (SRE) with deep expertise in AWS networking, infrastructure automation, and production system reliability and ability to lead when neededd. This role demands a strong grasp of observability, operational excellence, and the ability to drive the adoption of DevOps/SRE best practices across engineering teams. You will be instrumental in shaping SLIs/SLOs, defining our DevOps maturity roadmap, and building robust, scalable infrastructure using Terraform, Lambda, Step Functions, and more.
Youâ€™ll be leading a team of SREs and collaborating closely with DevOps, Security, and Application teams to ensure reliable delivery and availability of services. Lead and mentor a team of SREs in developing scalable infrastructure and operational processes. Design and implement SLIs, SLOs, and Error Budgets across critical services and evangelize them across product teams. Architect and manage AWS networking environments including VPCs, Transit Gateways, Route 53, VPNs, NACLs, and Security Groups. Manage and monitor Palo Alto and FortiGate firewalls, and integrate them with cloud environments for hybrid network visibility. Define and evolve DevOps maturity models, guiding teams toward higher automation and reliability. Build and manage observability dashboards using Grafana, CloudWatch and Datadog to track application and infrastructure health. Implement and maintain Infrastructure as Code (IaC) using Terraform to automate cloud deployments across environments. Develop and maintain serverless applications using AWS Lambda and Step Functions to support platform automation and operations. Collaborate with developers to define GitLab CI/CD pipelines and streamline the build, test, and deployment lifecycle. Champion incident response, blameless postmortems, and continuous improvement initiatives. Write scripts in Python or Bash to automate tasks and integrate systems
 REQUIREMENTS 
7+ years in SRE, DevOps, or Systems Engineering roles with increasing responsibility.
Proven experience managing AWS production environments with a focus on networking.
In-depth knowledge of Palo Alto and/or FortiGate firewall management and troubleshooting.
Expertise in monitoring and observability tools, including Grafana and Datadog.
Hands-on experience with Terraform in managing cloud infrastructure at scale.
Experience building and deploying serverless architectures using Lambda and Step Functions.
Demonstrated understanding of SLI/SLO design, error budgets, and reliability metrics.
Strong understanding of CI/CD principles and tools like GitLab CI/CD.
Proficiency in scripting using Python or Bash.
Nice to have Skills:
AWS Certifications (e.g., Solutions Architect, Advanced Networking, DevOps Engineer)
Familiarity with DevOps/SRE maturity models and implementing organizational transformation.
Experience with compliance frameworks (SOC2, ISO 27001, etc.) as they pertain to infrastructure reliability.
Familiarity with container orchestration is a plus.

Experience required 7 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4259896332,https://www.linkedin.com/jobs/view/4259896332,Pending,Unknown,2025-07-09 00:20:34.782892,Asking for Security clearance,"
About the job
Job Title: DevOps Engineer
Locations: Annapolis Junction, MD
Job Type: Onsite
 Full-Time/Permanent job position
  JOB DESCRIPTION:

 Senior level candidate needed with strong Kubernetes, Terraform and AWS. Top Secret/SCI Clearance/FSP Required.
   Role Responsibilities:
Provide optimization and automation across multiple platforms and applications.
Drive consistency for deployment and build processes.
Utilize modern tools like Jenkins, Docker, Kubernetes, Amazon Web Services, Ansible, Terraform, Python, Linux, and much more.
You have worked with teams before on large and demonstrable projects (preferably built on with AWS and familiarity with scripting languages such as Bash, Ruby, Python).
Familiarity with containerization tools like Docker and Kubernetes.
You understand how to set up a CI/CD pipeline.
You understand Agile software development and DevOps practices and can work closely with your peers other mid-to large size teams.
Focus on understanding customers' needs and translating those needs from product specifications into functional, production ready code and infrastructure.
The following skills are required: AWS (S3, VPCs & Networking, EC2, ECS/EKS). Containerization (Docker, k8s, Registries). IaC (Terraform/Cloud Formation). CI/CD (Jenkins/ GitHub Actions).
You are self-driven, self-learner willing to share knowledge and participate actively in a team environment.
CWIP IAT Level I required.
Experience above is required with a bachelorâ€™s degree.
4 years of additional experience can be substituted for a bachelorâ€™s degree.
4 years less experience is ok for candidates with a graduate degree.

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4264256225,https://www.linkedin.com/jobs/view/4264256225,Pending,Unknown,2025-07-09 00:20:43.295848,Required experience is high,"
About the job
DevOps Engineer with Terraform Experience. Hybrid Model. 
Long Term W2 Contract in Jersey City or Pennington, NJ

8+ years of DevOps experience
Strong experience in Ansible, Jenkins, Terraform
Experience taking manual tasks/processes and automated at the enterprise level.
Demonstrated expertise of scripting via common solutions such as Python and PowerShell.
Exposure to working in environment that is heavy on operations technology (automation, optimization, rapid development)
Demonstrated expert level of RHEL Linux OS and LDAP Directory administration.
Solid understanding and demonstrable expertise delivering Linux based automated solutions.
Solid understanding of infrastructure (hardware, network, storage).
Good understanding of agile methodology and associated toolset (Jira, Bitbucket, Jenkins, etc.)
Develop and maintain automated solutions leveraging Terraform, Jenkins, Ansible, Git
Managing and optimizing cloud infrastructure on platforms like Azure and AWS

Experience required 8 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4262169934,https://www.linkedin.com/jobs/view/4262169934,Pending,Unknown,2025-07-09 00:20:53.165507,Asking for Security clearance,"
About the job
Position: DevOps Engineer
Location: Remote â€“ Chicago area 
Job Type: 6-Month W2 Contract 
Compensation: $50-$54/hr 

Description: 
The Infrastructure Engineer works on holistic engineering deliverables across different stages of the product lifecycle and determines technology patterns for the overall solution. This role takes the lead in guiding more junior engineers and is a role model in fostering the adoption of new technologies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. 
 Qualifications: 
Experience with Kubernetes - OpenShift(OCP) at a platform level
Experience with any one OpenShift / K8s supported Networking CNI. (Plus if you know Calico ) 
Experience with AWS infrastructure (VPC / Security groups / EC2 / Storages / Load Balancers) 
Experience doing OCP upgrades and creating OCP Clusters
Experience of platform automation products like RH ACM / Terraform / Ansible
Responsible for incident resolution and Pager Support on a rotation basis.
Achieves product commitments (and influences others to do the same) by using informal leadership & highly developed communication skills and contributes to or led technology communities.
Uses automation, system tools, open-source solutions, observability and 'security first' principles in daily work 
Contributes to team agile ceremonies, leads demos and presentations, helps new engineers learn established norms 
Responsible for pager support once every quarter.
Initiates high level solution design approaches, and guides team to achieve desired key software delivery capabilities using automated, coded enterprise and observability 
Participates in internal speaking and advocacy events 
Supports research activities to adopt new technology solutions in ways of developing new capabilities 
Continues professional education and creates opportunities for core product teams to learn engineering best practices 
Coaches immediate chapter and actively fosters the adoption of new technologies

Preferred Qualifications 
Bonus Points If You Have: 
Kubernetes certification like - CKA or CKAD and AWS certification.
Application programming skills in Golang, Java, etc.
Understanding of k8s operator model. 
Scripting languages like shell / Helm modules or some programming experience. 
Diagraming skills such as sequence diagrams, flowcharts, etc.
Concepts of secrets/credential management for Applications and systems - such as use of HashiCorp Vault
Operators in Kubernetes/OCP

TECHNICAL SKILLS
Must Have
Ansible
AWS
calico
CICD
Firewalls
Kubernetes
Kubernetes Openshift
Scripting

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4262158969,https://www.linkedin.com/jobs/view/4262158969,Pending,Unknown,2025-07-09 00:21:04.652851,Required experience is high,"
About the job
Sr. DevOps Engineer (Azure, GitHub Action, Ansible)
Fully Remote: Must be in EST or CST time zone
6-month contract-to-hire

Optomi, in partnership with our premier client in the insurance industry, is seeking an experienced DevOps Engineer to join their team for a remote role! The DevOps Engineer will support multiple product and development teams in automating infrastructure, streamlining CI/CD pipelines, managing deployments, and ensuring production readiness. The ideal candidate will bring deep expertise in Azure, Terraform, Ansible, and GitHub Actions, along with strong scripting and automation skills. You will collaborate with product managers, architects, developers, and stakeholders in a fast-paced agile environment to deliver scalable and resilient cloud infrastructure solutions.

Key Responsibilities:
Design, build, and maintain cloud infrastructure using Azure services (Identity, Networking, Compute, Storage, Automation, Disaster Recovery).
Develop and maintain infrastructure-as-code using Terraform and Ansible.
Create, enhance, and support CI/CD pipelines using GitHub Actions and GitHub Enterprise.
Write scripts and automation tools using Python, Bash, and PowerShell.
Operate and scale container platforms; support containerization and migration efforts.
Manage high-availability, cloud-based server architectures and enforce deployment standards.
Implement monitoring and alerting strategies; define telemetry and observability baselines.
Partner with cross-functional teams to troubleshoot and resolve production issues.
Apply DevOps and Agile best practices for continuous integration and delivery.
Document infrastructure components, automation tools, and deployment procedures.
Provide mentoring and technical guidance to junior DevOps engineers.

Required Qualifications:
7+ years of IT experience, with at least 2+ years in DevOps automation/integration.
Proven experience with:
Microsoft Azure (IaaS, PaaS, Networking, Identity, and Resource Management)
Terraform (Infrastructure as Code)
Ansible (Configuration Management)
GitHub Actions and GitHub Enterprise
Scripting and automation expertise in Python, Bash, and PowerShell.
Strong Linux administration skills and understanding of system internals.
Familiarity with software development life cycles and release management.
Experience with monitoring tools and defining performance metrics and thresholds.
Strong understanding of networking concepts and protocols.
Comfortable working in multi-cloud or hybrid environments.
Excellent problem-solving, communication, and documentation skills.

Preferred Qualifications:
Bachelorâ€™s degree in Computer Science or related field (or equivalent experience).
Relevant certifications (e.g., Azure Administrator, Terraform Associate, RHCE).
Experience in regulated or enterprise environments (e.g., insurance or finance).
Prior experience in Agile environments and test-driven development methodologies.

Experience required 7 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4261824324,https://www.linkedin.com/jobs/view/4261824324,Previous resume,Unknown,2025-07-09 00:21:50.982831,Problem in Easy Applying,"Seems like stuck in a continuous loop of next, probably because of new questions.",Easy Applied,4261824324 - Failed at questions - 2025-07-09 00:21:47.692521.png
4262160401,https://www.linkedin.com/jobs/view/4262160401,Pending,Unknown,2025-07-09 00:22:13.941548,Required experience is high,"
About the job
Optomi, in partnership with a global leader in IT infrastructure services, is seeking a Lead DevOps Engineer to drive the future of automation and infrastructure in an Azure-native environment.

This is a high-impact, hybrid technical/strategic role where youâ€™ll lead intelligent automation initiatives, embed AI capabilities into CI/CD and infrastructure workflows, and guide a senior DevOps engineer. Youâ€™ll collaborate across architecture, platform, and software teams to modernize operations and scale SaaS-focused solutions using Azure Fabric and Microsoft-native tools.


Key Responsibilities
Architect and scale CI/CD pipelines using GitHub Actions and Azure DevOps tools, embedding AI/ML models for intelligent testing, deployment, and observability.
Lead implementation of predictive monitoring and alerting with Dynatrace and Azure Monitor to enable self-healing systems.
Define and execute infrastructure automation strategies with Terraform, aligning with governance and long-term scalability goals.
Mentor and guide DevOps engineers, fostering autonomy, technical excellence, and innovation.
Collaborate with architecture, data, and engineering teams to align automation strategy with enterprise-wide SaaS and Azure Fabric adoption.
Evaluate and adopt emerging Azure AI services (e.g., Azure Machine Learning, Cognitive Services) to enhance infrastructure intelligence.
Serve as liaison across teams, driving DevOps priorities, best practices, and automation-first culture.

Core Requirements
7+ years in DevOps or cloud engineering with hands-on technical leadership experience.
Deep expertise with GitHub Actions or similar CI/CD tooling in enterprise Azure environments.
Advanced experience with Terraform for large-scale infrastructure automation.
Proven knowledge of Dynatrace, Azure Monitor, or similar observability tools with AI/ML-based alerting strategies.
Demonstrated ability to mentor engineers, influence technical culture, and lead DevOps transformation.
Hands-on experience with Azure AI services and embedding intelligence into infrastructure or DevOps workflows.
Excellent communication skillsâ€”able to work cross-functionally and drive clarity from ambiguity.

Preferred Qualifications
Experience with Azure Fabric and transitioning to SaaS-native architectures.
Background in both infrastructure and software engineering with an SRE/DevOps mindset.
Familiarity with data platform automation and scaling distributed systems.
Ability to balance architectural governance with flexibility and innovation.

Experience required 7 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4260739147,https://www.linkedin.com/jobs/view/4260739147,Pending,Unknown,2025-07-09 00:22:28.154585,Asking for Security clearance,"
About the job
Genpact (NYSE: G) is a global professional services and solutions firm delivering outcomes that shape the future. Our 125,000+ people across 30+ countries are driven by our innate curiosity, entrepreneurial agility, and desire to create lasting value for clients. Powered by our purpose â€“ the relentless pursuit of a world that works better for people â€“ we serve and transform leading enterprises, including the Fortune Global 500, with our deep business and industry knowledge, digital operations services, and expertise in data, technology, and AI. 
 Inviting applications for the role of 
Core Platform Engineer â€“ Kubernetes, K3s, Docker, OpenShift.
The ideal candidate will be responsible for Core Platform Engineer to design, build, and maintain container orchestration and infrastructure platforms using Kubernetes, K3s, Docker, and OpenShift..
 Responsibilities
Â· Design and maintain production-grade Kubernetes clusters (on-prem and/or cloud).
Â· Deploy and manage lightweight K3s clusters for edge or resource-constrained environments.
Â· Implement and maintain Docker-based container runtimes, images, and registries.
Â· Manage OpenShift clusters, including setup, operator lifecycle management, security policies, and application deployment strategies.
Â· Develop and manage CI/CD pipelines integrated with Kubernetes/OpenShift (e.g., Tekton, ArgoCD, GitLab CI).
Â· Implement Infrastructure as Code (IaC) using tools like Terraform, Helm, and Ansible.
Â· Secure container environments through network policies, role-based access control (RBAC), secrets management, and vulnerability scanning.
Â· Work closely with application teams to onboard workloads, troubleshoot issues, and optimize resource usage.
Â· Participate in on-call rotations and provide L3 support for platform-related incidents.
Â· Develop and maintain Linux shell scripts for automation of deployments, monitoring, and maintenance tasks.
  Qualifications we seek in you!
Minimum Qualifications
Â· BE/B Tech/MCA
Â· Excellent written and verbal communication skills
Â· Min 7 years of experience.
Â· Experience in Finance Domain
   Preferred Qualifications/ Skills
Â· Strong hands-on experience with Kubernetes (EKS, AKS, GKE, or vanilla) cluster administration.
Â· Experience with K3s in edge computing, dev/test environments, or IoT scenarios.
Â· Proficiency in Docker image creation, optimization, and lifecycle management.
Â· Solid experience with Red Hat OpenShift (v4+), including Operators, SCCs, Routes, and Service Mesh.
Â· Strong scripting/automation skills in Bash, Python, or Go.
Â· Familiarity with container storage, networking, and ingress controllers (e.g., NGINX, Istio, Traefik).
Â· Deep understanding of CI/CD tools and GitOps practices.
Â· Solid grasp of Linux internals, system performance tuning, and security best practices. 
Â· Work-from-Anywhere Roles â€“ â€œLos Angeles California-based candidates are not eligible for this roleâ€ 
Â· Location-based Roles (e.g., Richardson roles â€“ metro area can be adjusted by role location) â€“ â€œLos Angeles, California based candidates are not eligible for this role. area candidates are eligible for this role only.â€
 Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com . Follow us on Twitter, Facebook, LinkedIn, and YouTube.
Furthermore, please do note that Genpact does not charge fees to process job applications and applicants are not required to pay to participate in our hiring process in any other way. Examples of such scams include purchasing a 'starter kit,' paying to apply, or purchasing equipment or training.

Found ""Clearance"" or ""Polygraph"". Skipping this job!
",Skipped,Not Available
4260713690,https://www.linkedin.com/jobs/view/4260713690,Pending,Unknown,2025-07-09 00:22:30.582894,Required experience is high,"
About the job
Location: Hybrid Herndon, VA
Base Salary Range: $170,000 - $200,000 annually plus 25% annual bonus

Our client builds and operates LEO satellites for RF data collection and analysis. As a member of the Platform Engineering team, you will enable fellow team members to build secure, performant, efficient, and cost-effective systems and tools supporting the company's mission. The successful candidate will help shape the next generation platform by providing expert insights to improve the existing system and turn ideas into deployed production capabilities. The Principal Platform Engineer will report to the Director of Platform Engineering, and interface with directors and engineers throughout the Engineering organization.

Responsibilities -
Develop, deploy, and maintain critical infrastructure in AWS for the company's collection, processing, and analytics services.
Provide expert technical guidance and oversight across the entire company's platform architecture.
Collaborate across engineering teams to understand platform requirements, use cases, and functionality.
Design and improve platform architecture to meet the functional needs of the organization and ensure integrity and security of the systems and data.
Troubleshoot and perform root cause analysis on unexpected issues/outages.
Guide and mentor teammates to automate and simplify daily development and deployment processes.

Qualifications -
M.S. or B.S. in Computer Science or related engineering field or equivalent experience
10+ years professional experience
Broad knowledge of Infrastructure setup, automation and troubleshooting, with specific knowledge of the Amazon Web Services (AWS) technology stack; particularly deploying and maintaining EKS, EC2, RDS, S3/EBS/EFS.
A deep understanding of basic networking concepts relevant to Platform Engineering troubleshooting, including TCP/IP, UDP, HTTP, firewalls, basic routing concepts, and load balancers, with hands-on AWS networking experience
Knowledge of Linux operating systems and installing and configuring security patches, within containers and on servers/virtual machines
Deep understanding of development and security best-practices, utilizing least-privilege concepts for access control
Experience with Software/Systems Operations, to include managing and troubleshooting production systems
Experience deploying and configuring applications to run on Kubernetes clusters using Helm
Familiarity with writing and maintaining terraform modules to deploy infrastructure
Excellent written and oral communication skills

Preferred Skills -
Experience with Kubernetes advanced add-ons such as: ArgoCD, Kyverno, Cilium, and Crossplane
Experience migrating terraform modules to Crossplane compositions
Experience with Keycloak, Okta or other OIDC/SAML-based SSO & Auth services
Experience building and updating secure Docker images to deploy custom applications
Familiarity Metrics & Monitoring tooling (Grafana, Mimir, Loki, Tempo, or similar)
Experience with Tableau and Snowflake

Experience required 10 > Current Experience 6. Skipping this job!
",Skipped,Not Available
4264258655,https://www.linkedin.com/jobs/view/4264258655,Pending,Unknown,2025-07-09 00:22:32.954273,Required experience is high,"
About the job
Role : Azure DevOps Engineer
Location : California and Nevda ( Onsite) 
contract role 
Experience required : 13 years 

10+ years of experience in Cloud Engineering, DevOps, or related roles.
Strong expertise in Terraform IAC for Infrastructure as Code (IaC).
Proficiency in CI/CD tools like Jenkins, GitHub Actions, or GitLab CI/CD.
Knowledge of containerization technologies (Docker, Kubernetes).

Experience required 10 > Current Experience 6. Skipping this job!
",Skipped,Not Available
